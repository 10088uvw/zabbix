
# NetApp AFF A700 by HTTP

## Overview

For Zabbix version: 5.0 and higher  
The template to monitor SAN NetApp AFF A700 cluster by Zabbix HTTP agent.




This template was tested on:

- NetApp AFF A700, version 9.7
- Zabbix, version 5.0

## Setup

1\. Create host for AFF A700 with cluster management IP as the Zabbix agent interface.

2\. Link the template to the host.

3\. Customize macros values if needed.



## Zabbix configuration

No specific Zabbix configuration is required.

### Macros used

|Name|Description|Default|
|----|-----------|-------|
|{$HTTP.AGENT.TIMEOUT} |<p>The HTTP agent timeout to wait for a response from AFF700.</p> |`3s` |
|{$PASSWORD} |<p>AFF700 user password.</p> |`` |
|{$URL} |<p>AFF700 cluster URL address.</p> |`` |
|{$USERNAME} |<p>AFF700 user name.</p> |`` |

## Template links

There are no template links in this template.

## Discovery rules

|Name|Description|Type|Key and additional info|
|----|-----------|----|----|
|Nodes discovery |<p>-</p> |HTTP_AGENT |netapp.aff.nodes.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |
|Ethernet ports discovery |<p>-</p> |HTTP_AGENT |netapp.aff.ports.ether.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |
|FC ports discovery |<p>-</p> |HTTP_AGENT |netapp.aff.ports.fc.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |
|Disks discovery |<p>-</p> |HTTP_AGENT |netapp.aff.disks.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |
|Chassis discovery |<p>-</p> |HTTP_AGENT |netapp.aff.chassis.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |
|FRUs discovery |<p>-</p> |DEPENDENT |netapp.aff.frus.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|SVMs discovery |<p>-</p> |HTTP_AGENT |netapp.aff.svms.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |
|LUNs discovery |<p>-</p> |HTTP_AGENT |netapp.aff.luns.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |
|Volumes discovery |<p>-</p> |HTTP_AGENT |netapp.aff.volumes.discovery<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |

## Items collected

|Group|Name|Description|Type|Key and additional info|
|-----|----|-----------|----|---------------------|
|General |Cluster software version |<p>This returns the cluster version information. When the cluster has more than one node, the cluster version is equivalent to the lowest of generation, major, and minor versions on all nodes.</p> |DEPENDENT |netapp.aff.cluster.version<p>**Preprocessing**:</p><p>- JSONPATH: `$.version.full`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |Cluster name |<p>The name of the cluster.</p> |DEPENDENT |netapp.aff.cluster.name<p>**Preprocessing**:</p><p>- JSONPATH: `$.name`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |Cluster location |<p>The location of the cluster.</p> |DEPENDENT |netapp.aff.cluster.location<p>**Preprocessing**:</p><p>- JSONPATH: `$.location`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |Cluster status |<p>The status of the cluster: ok, error, partial_no_data, partial_no_response, partial_other_error, negative_delta, backfilled_data, inconsistent_delta_time, inconsistent_old_data.</p> |DEPENDENT |netapp.aff.cluster.status<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.status`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |Cluster throughput other |<p>Throughput bytes observed at the storage object. Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.</p> |DEPENDENT |netapp.aff.cluster.statistics.throughput.other.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.throughput_raw.other`</p><p>- CHANGE_PER_SECOND |
|General |Cluster throughput read |<p>Throughput bytes observed at the storage object. Performance metric for read I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.throughput.read.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.throughput_raw.read`</p><p>- CHANGE_PER_SECOND |
|General |Cluster throughput write |<p>Throughput bytes observed at the storage object. Peformance metric for write I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.throughput.write.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.throughput_raw.write`</p><p>- CHANGE_PER_SECOND |
|General |Cluster throughput total |<p>Throughput bytes observed at the storage object. Performance metric aggregated over all types of I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.throughput.total.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.throughput_raw.total`</p><p>- CHANGE_PER_SECOND |
|General |Cluster iops other |<p>The number of I/O operations observed at the storage object. Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.</p> |DEPENDENT |netapp.aff.cluster.statistics.iops.other.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.iops_raw.other`</p><p>- CHANGE_PER_SECOND |
|General |Cluster iops read |<p>The number of I/O operations observed at the storage object. Performance metric for read I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.iops.read.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.iops_raw.read`</p><p>- CHANGE_PER_SECOND |
|General |Cluster iops write |<p>The number of I/O operations observed at the storage object. Peformance metric for write I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.iops.write.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.iops_raw.write`</p><p>- CHANGE_PER_SECOND |
|General |Cluster iops total |<p>The number of I/O operations observed at the storage object. Performance metric aggregated over all types of I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.iops.total.rate<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.iops_raw.total`</p><p>- CHANGE_PER_SECOND |
|General |Cluster latency other |<p>The latency in seconds observed at the storage object. Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.</p> |DEPENDENT |netapp.aff.cluster.statistics.latency.other<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.latency_raw.other`</p><p>- MULTIPLIER: `0.000001`</p><p>- CHANGE_PER_SECOND |
|General |Cluster latency read |<p>The latency in seconds observed at the storage object. Performance metric for read I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.latency.read<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.latency_raw.read`</p><p>- MULTIPLIER: `0.000001`</p><p>- CHANGE_PER_SECOND |
|General |Cluster latency write |<p>The latency in seconds observed at the storage object. Peformance metric for write I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.latency.write<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.latency_raw.write`</p><p>- MULTIPLIER: `0.000001`</p><p>- CHANGE_PER_SECOND |
|General |Cluster latency total |<p>The latency in seconds observed at the storage object. Performance metric aggregated over all types of I/O operations.</p> |DEPENDENT |netapp.aff.cluster.statistics.latency.total<p>**Preprocessing**:</p><p>- JSONPATH: `$.statistics.latency_raw.total`</p><p>- MULTIPLIER: `0.000001`</p><p>- CHANGE_PER_SECOND |
|General |: {#NODENAME} software version |<p>This returns the cluster version information. When the cluster has more than one node, the cluster version is equivalent to the lowest of generation, major, and minor versions on all nodes.</p> |DEPENDENT |netapp.aff.node.version[{#NODENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#NODENAME}')].version.full.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |: {#NODENAME} location |<p>The location of the node.</p> |DEPENDENT |netapp.aff.nodes.location[{#NODENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#NODENAME}')].location.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |: {#NODENAME} state |<p>State of the node:</p><p>up - Node is up and operational.</p><p>booting - Node is booting up.</p><p>down - Node has stopped or is dumping core.</p><p>taken_over - Node has been taken over by its HA partner and is not yet waiting for giveback.</p><p>waiting_for_giveback - Node has been taken over by its HA partner and is waiting for the HA partner to giveback disks.</p><p>degraded - Node has one or more critical services offline.</p><p>unknown - Node or its HA partner cannot be contacted and there is no information on the node’s state.</p> |DEPENDENT |netapp.aff.nodes.state[{#NODENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#NODENAME}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |: {#NODENAME} membership |<p>Possible values:</p><p>  available - If a node is available, this means it is detected on the internal cluster network and can be added to the cluster. Nodes that have a membership of “available” are not returned when a GET request is called when the cluster exists. A query on the “membership” property for available must be provided to scan for nodes on the cluster network. Nodes that have a membership of “available” are returned automatically before a cluster is created.</p><p>  joining - Joining nodes are in the process of being added to the cluster. The node may be progressing through the steps to become a member or might have failed. The job to add the node or create the cluster provides details on the current progress of the node.</p><p>  member - Nodes that are members have successfully joined the cluster.</p> |DEPENDENT |netapp.aff.nodes.membership[{#NODENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#NODENAME}')].membership.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |: {#NODENAME} uptime |<p>The total time, in seconds, that the node has been up.</p> |DEPENDENT |netapp.aff.nodes.uptime[{#NODENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#NODENAME}')].uptime.first()`</p> |
|General |: {#NODENAME} controller.over_temperature |<p>Specifies whether the hardware is currently operating outside of its recommended temperature range. The hardware shuts down if the temperature exceeds critical thresholds. Possible values: over, normal</p> |DEPENDENT |netapp.aff.nodes.controller.over_temperature[{#NODENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#NODENAME}')].controller.over_temperature.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#ETHPORTNAME}: State |<p>The operational state of the port. Possible values: up, down.</p> |DEPENDENT |netapp.aff.port.eth.state[{#NODENAME},{#ETHPORTNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#ETHPORTNAME}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#FCPORTNAME}: Description |<p>A description of the FC port.</p> |DEPENDENT |netapp.aff.port.fc.description[{#NODENAME},{#FCPORTNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#FCPORTNAME}')].description.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#FCPORTNAME}: State |<p>The operational state of the FC port. Possible values:</p><p>startup - The port is booting up.</p><p>link_not_connected - The port has finished initialization, but a link with the fabric is not established.</p><p>online - The port is initialized and a link with the fabric has been established.</p><p>link_disconnected - The link was present at one point on this port but is currently not established.</p><p>offlined_by_user - The port is administratively disabled.</p><p>offlined_by_system - The port is set to offline by the system. This happens when the port encounters too many errors.</p><p>node_offline - The state information for the port cannot be retrieved. The node is offline or inaccessible.</p> |DEPENDENT |netapp.aff.port.fc.state[{#NODENAME},{#FCPORTNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#FCPORTNAME}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#DISKNAME}: State |<p>The state of the disk. Possible values: broken, copy, maintenance, partner, pending, present, reconstructing, removed, spare, unfail, zeroing</p> |DEPENDENT |netapp.aff.disk.state[{#NODENAME},{#DISKNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#DISKNAME}'&&@.node.name=='{#NODENAME}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#ID}: State |<p>The chassis state: ok, error.</p> |DEPENDENT |netapp.aff.chassis.state[{#ID}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.id=='{#ID}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#FRUID}: State |<p>The FRU state: ok, error.</p> |DEPENDENT |netapp.aff.chassis.fru.state[{#CHASSISID},{#FRUID}]<p>**Preprocessing**:</p><p>- JSONPATH: `$[?(@.id=='{#FRUID}'&&@.chassisId=='{#CHASSISID}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#SVMNAME}: State |<p>SVM state: starting, running, stopping, stopped, deleting.</p> |DEPENDENT |netapp.aff.svm.state[{#SVMNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#SVMNAME}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#SVMNAME}: Comment |<p>The comment for the SVM.</p> |DEPENDENT |netapp.aff.svm.comment[{#SVMNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#SVMNAME}')].comment.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |LUN "{#LUNNAME}": State |<p>The state of the LUN. Normal states for a LUN are online and offline. Other states indicate errors. Possible values: foreign_lun_error, nvfail, offline, online, space_error.</p> |DEPENDENT |netapp.aff.lun.status.state[{#SVMNAME},{#LUNNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.svm.name=='{#SVMNAME}'&&@.name=='{#LUNNAME}')].status.state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |LUN "{#LUNNAME}": Container state |<p>The state of the volume and aggregate that contain the LUN: online, aggregate_offline, volume_offline. LUNs are only available when their containers are available.</p> |DEPENDENT |netapp.aff.lun.status.container_state[{#SVMNAME},{#LUNNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.svm.name=='{#SVMNAME}'&&@.name=='{#LUNNAME}')].status.container_state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |LUN "{#LUNNAME}": Space size |<p>The total provisioned size of the LUN.</p> |DEPENDENT |netapp.aff.lun.space.size[{#SVMNAME},{#LUNNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.svm.name=='{#SVMNAME}'&&@.name=='{#LUNNAME}')].space.size.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |LUN "{#LUNNAME}": Space used |<p>The amount of space consumed by the main data stream of the LUN.</p> |DEPENDENT |netapp.aff.lun.space.used[{#SVMNAME},{#LUNNAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.svm.name=='{#SVMNAME}'&&@.name=='{#LUNNAME}')].space.used.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: Comment |<p>A comment for the volume.</p> |DEPENDENT |netapp.aff.volume.comment[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].comment.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: State |<p>Volume state. A volume can only be brought online if it is offline. Taking a volume offline removes its junction path. The ‘mixed’ state applies to FlexGroup volumes only and cannot be specified as a target state. An ‘error’ state implies that the volume is not in a state to serve data.</p> |DEPENDENT |netapp.aff.volume.state[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].state.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: Type |<p>Type of the volume.</p><p>rw ‐ read-write volume.</p><p>dp ‐ data-protection volume.</p><p>ls ‐ load-sharing dp volume.</p> |DEPENDENT |netapp.aff.volume.type[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].type.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: SVM name |<p>The volume belongs this SVM.</p> |DEPENDENT |netapp.aff.volume.svm_name[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].svm.name.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: Space size |<p>Total provisioned size. The default size is equal to the minimum size of 20MB, in bytes.</p> |DEPENDENT |netapp.aff.volume.space_size[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].space.size.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: Available size |<p>The available space, in bytes.</p> |DEPENDENT |netapp.aff.volume.space_available[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].space.available.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: Used size |<p>The virtual space used (includes volume reserves) before storage efficiency, in bytes.</p> |DEPENDENT |netapp.aff.volume.space_used[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].space.used.first()`</p><p>- DISCARD_UNCHANGED_HEARTBEAT: `6h`</p> |
|General |{#VOLUMENAME}: Volume throughput other |<p>Throughput bytes observed at the storage object. Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.</p> |DEPENDENT |netapp.aff.volume.statistics.throughput.other.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.throughput_raw.other.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume throughput read |<p>Throughput bytes observed at the storage object. Performance metric for read I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.throughput.read.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.throughput_raw.read.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume throughput write |<p>Throughput bytes observed at the storage object. Peformance metric for write I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.throughput.write.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.throughput_raw.write.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume throughput total |<p>Throughput bytes observed at the storage object. Performance metric aggregated over all types of I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.throughput.total.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.throughput_raw.total.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume iops other |<p>The number of I/O operations observed at the storage object. Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.</p> |DEPENDENT |netapp.aff.volume.statistics.iops.other.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.iops_raw.other.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume iops read |<p>The number of I/O operations observed at the storage object. Performance metric for read I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.iops.read.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.iops_raw.read.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume iops write |<p>The number of I/O operations observed at the storage object. Peformance metric for write I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.iops.write.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.iops_raw.write.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume iops total |<p>The number of I/O operations observed at the storage object. Performance metric aggregated over all types of I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.iops.total.rate[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.iops_raw.total.first()`</p><p>- CHANGE_PER_SECOND |
|General |{#VOLUMENAME}: Volume latency other |<p>The raw latency in microseconds observed at the storage object. Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.</p> |DEPENDENT |netapp.aff.volume.statistics.latency.other[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.latency_raw.other.first()`</p><p>- MULTIPLIER: `0.000001`</p><p>- SIMPLE_CHANGE |
|General |{#VOLUMENAME}: Volume latency read |<p>The raw latency in microseconds observed at the storage object. Performance metric for read I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.latency.read[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.latency_raw.read.first()`</p><p>- MULTIPLIER: `0.000001`</p><p>- SIMPLE_CHANGE |
|General |{#VOLUMENAME}: Volume latency write |<p>The raw latency in microseconds observed at the storage object. Peformance metric for write I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.latency.write[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.latency_raw.write.first()`</p><p>- MULTIPLIER: `0.000001`</p><p>- SIMPLE_CHANGE |
|General |{#VOLUMENAME}: Volume latency total |<p>The raw latency in microseconds observed at the storage object. Performance metric aggregated over all types of I/O operations.</p> |DEPENDENT |netapp.aff.volume.statistics.latency.total[{#VOLUMENAME}]<p>**Preprocessing**:</p><p>- JSONPATH: `$.records[?(@.name=='{#VOLUMENAME}')].statistics.latency_raw.total.first()`</p><p>- MULTIPLIER: `0.000001`</p><p>- SIMPLE_CHANGE |
|Zabbix_raw_items |Get cluster metrics |<p>-</p> |HTTP_AGENT |netapp.aff.cluster.get |
|Zabbix_raw_items |Get nodes metrics |<p>-</p> |HTTP_AGENT |netapp.aff.nodes.get |
|Zabbix_raw_items |Get disks metrics |<p>-</p> |HTTP_AGENT |netapp.aff.disks.get |
|Zabbix_raw_items |Get volumes metrics |<p>-</p> |HTTP_AGENT |netapp.aff.volumes.get |
|Zabbix_raw_items |Get ehternet ports metrics |<p>-</p> |HTTP_AGENT |netapp.aff.ports.eth.get |
|Zabbix_raw_items |Get FC ports metrics |<p>-</p> |HTTP_AGENT |netapp.aff.ports.fc.get |
|Zabbix_raw_items |Get SVMs metrics |<p>-</p> |HTTP_AGENT |netapp.aff.svms.get |
|Zabbix_raw_items |Get LUNs metrics |<p>-</p> |HTTP_AGENT |netapp.aff.luns.get |
|Zabbix_raw_items |Get Chassis metrics |<p>-</p> |HTTP_AGENT |netapp.aff.chassis.get |
|Zabbix_raw_items |Get FRUs metrics |<p>-</p> |HTTP_AGENT |netapp.aff.frus.get<p>**Preprocessing**:</p><p>- JAVASCRIPT: `Text is too long. Please see the template.`</p> |

## Triggers

|Name|Description|Expression|Severity|Dependencies and additional info|
|----|-----------|----|----|----|
|Version has changed (new version: {ITEM.VALUE}) |<p>__RESOURCE__ version has changed. Ack to close.</p> |`{TEMPLATE_NAME:netapp.aff.cluster.version.diff()}=1 and {TEMPLATE_NAME:netapp.aff.cluster.version.strlen()}>0` |INFO |<p>Manual close: YES</p> |
|Cluster has status different from normal |<p>Any errors associated with the sample. For example, if the aggregation of data over multiple nodes fails then any of the partial errors might be returned, “ok” on success, or “error” on any internal uncategorized failure. Whenever a sample collection is missed but done at a later time, it is back filled to the previous 15 second timestamp and tagged with "backfilled_data". “Inconsistent_ delta_time” is encountered when the time between two collections is not the same for all nodes. Therefore, the aggregated value might be over or under inflated. “Negative_delta” is returned when an expected monotonically increasing value has decreased in value. “Inconsistent_old_data” is returned when one or more nodes does not have the latest data.</p> |`({TEMPLATE_NAME:netapp.aff.cluster.status.last()}<>"ok")` |AVERAGE | |
|: Version has changed (new version: {ITEM.VALUE}) |<p> version has changed. Ack to close.</p> |`{TEMPLATE_NAME:netapp.aff.node.version[{#NODENAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.node.version[{#NODENAME}].strlen()}>0` |INFO |<p>Manual close: YES</p> |
|: Node {#NODENAME} has state different from normal |<p>The state of the node is different from up:</p><p>booting - Node is booting up.</p><p>down - Node has stopped or is dumping core.</p><p>taken_over - Node has been taken over by its HA partner and is not yet waiting for giveback.</p><p>waiting_for_giveback - Node has been taken over by its HA partner and is waiting for the HA partner to giveback disks.</p><p>degraded - Node has one or more critical services offline.</p><p>unknown - Node or its HA partner cannot be contacted and there is no information on the node’s state.</p> |`({TEMPLATE_NAME:netapp.aff.nodes.state[{#NODENAME}].last()}<>"up")` |AVERAGE | |
|: Node {#NODENAME} has been restarted (uptime < 10m) |<p>Uptime is less than 10 minutes</p> |`{TEMPLATE_NAME:netapp.aff.nodes.uptime[{#NODENAME}].last()}<10m` |INFO |<p>Manual close: YES</p> |
|: Node {#NODENAME} has over temperature |<p>The hardware shuts down if the temperature exceeds critical thresholds(item's value is "over").</p> |`({TEMPLATE_NAME:netapp.aff.nodes.controller.over_temperature[{#NODENAME}].last()}<>"normal")` |AVERAGE | |
|{#ETHPORTNAME}: Node {#NODENAME} Ethernet port "{#ETHPORTNAME}" is down |<p>Something wrong with the ethernet port.</p> |`({TEMPLATE_NAME:netapp.aff.port.eth.state[{#NODENAME},{#ETHPORTNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.port.eth.state[{#NODENAME},{#ETHPORTNAME}].last()}="down")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.port.eth.state[{#NODENAME},{#ETHPORTNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.port.eth.state[{#NODENAME},{#ETHPORTNAME}].last()}="up")` |AVERAGE |<p>Manual close: YES</p> |
|{#FCPORTNAME}: Node "{#NODENAME}" FC port "{#FCPORTNAME}" has state different from "online" |<p>Something wrong with the ethernet port.</p> |`({TEMPLATE_NAME:netapp.aff.port.fc.state[{#NODENAME},{#FCPORTNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.port.fc.state[{#NODENAME},{#FCPORTNAME}].last()}<>"online")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.port.fc.state[{#NODENAME},{#FCPORTNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.port.fc.state[{#NODENAME},{#FCPORTNAME}].last()}="online")` |AVERAGE |<p>Manual close: YES</p> |
|{#DISKNAME}: Node "{#NODENAME}" Disk "{#DISKNAME}" has state different from "present" |<p>Something wrong with the disk.</p> |`({TEMPLATE_NAME:netapp.aff.disk.state[{#NODENAME},{#DISKNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.disk.state[{#NODENAME},{#DISKNAME}].last()}<>"present")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.disk.state[{#NODENAME},{#DISKNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.disk.state[{#NODENAME},{#DISKNAME}].last()}="present")` |AVERAGE |<p>Manual close: YES</p> |
|{#ID}: Chassis "{#ID}" has something errors |<p>Something wrong with the chassis.</p> |`({TEMPLATE_NAME:netapp.aff.chassis.state[{#ID}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.chassis.state[{#ID}].last()}="error")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.chassis.state[{#ID}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.chassis.state[{#ID}].last()}="ok")` |AVERAGE |<p>Manual close: YES</p> |
|{#FRUID}: Chassis "{#ID}" "{#FRUID}" state is error |<p>Something wrong with the FRU.</p> |`({TEMPLATE_NAME:netapp.aff.chassis.fru.state[{#CHASSISID},{#FRUID}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.chassis.fru.state[{#CHASSISID},{#FRUID}].last()}="error")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.chassis.fru.state[{#CHASSISID},{#FRUID}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.chassis.fru.state[{#CHASSISID},{#FRUID}].last()}="ok")` |AVERAGE |<p>Manual close: YES</p> |
|{#SVMNAME}: SVM "{#SVMNAME}" has abnormal state |<p>Something wrong with the SVM.</p> |`({TEMPLATE_NAME:netapp.aff.svm.state[{#SVMNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.svm.state[{#SVMNAME}].last()}<>"running")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.svm.state[{#SVMNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.svm.state[{#SVMNAME}].last()}="running")` |AVERAGE |<p>Manual close: YES</p> |
|LUN "{#LUNNAME}": SVM "{#SVMNAME}" LUN "{#LUNNAME}" has abnormal state |<p>Normal states for a LUN are online and offline. Other states indicate errors.</p> |`({TEMPLATE_NAME:netapp.aff.lun.status.state[{#SVMNAME},{#LUNNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.lun.status.state[{#SVMNAME},{#LUNNAME}].last()}<>"online")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.lun.status.state[{#SVMNAME},{#LUNNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.lun.status.state[{#SVMNAME},{#LUNNAME}].last()}="online")` |AVERAGE |<p>Manual close: YES</p> |
|LUN "{#LUNNAME}": SVM "{#SVMNAME}" LUN "{#LUNNAME}" has abnormal container state |<p>LUNs are only available when their containers are available.</p> |`({TEMPLATE_NAME:netapp.aff.lun.status.container_state[{#SVMNAME},{#LUNNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.lun.status.container_state[{#SVMNAME},{#LUNNAME}].last()}<>"online")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.lun.status.container_state[{#SVMNAME},{#LUNNAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.lun.status.container_state[{#SVMNAME},{#LUNNAME}].last()}="online")` |AVERAGE |<p>Manual close: YES</p> |
|{#VOLUMENAME}: Volume "{#VOLUMENAME}" has abnormal state |<p>A volume can only be brought online if it is offline. Taking a volume offline removes its junction path. The ‘mixed’ state applies to FlexGroup volumes only and cannot be specified as a target state. An ‘error’ state implies that the volume is not in a state to serve data.</p> |`({TEMPLATE_NAME:netapp.aff.volume.state[{#VOLUMENAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.volume.state[{#VOLUMENAME}].last()}<>"online")`<p>Recovery expression:</p>`({TEMPLATE_NAME:netapp.aff.volume.state[{#VOLUMENAME}].diff()}=1 and {TEMPLATE_NAME:netapp.aff.volume.state[{#VOLUMENAME}].last()}="online")` |AVERAGE |<p>Manual close: YES</p> |

## Feedback

Please report any issues with the template at https://support.zabbix.com

You can also provide a feedback, discuss the template or ask for help with it at [ZABBIX forums](https://www.zabbix.com/forum/zabbix-suggestions-and-feedback/).

